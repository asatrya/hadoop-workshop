version: "3"
services:
  namenode:
    image: trivadis/apache-hadoop-namenode:2.0.0-hadoop3.1.1-java8
    container_name: namenode
    hostname: namenode
    volumes:
      - ./container-volume/namenode:/hadoop/dfs/name
      - ./data-transfer:/data-transfer
    ports:
      - "9870:9870"
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./conf/hadoop.env
    restart: always

  datanode-1:
    image: trivadis/apache-hadoop-datanode:2.0.0-hadoop3.1.1-java8
    container_name: datanode-1
    volumes:
      - ./container-volume/datanode-1:/hadoop/dfs/data
    ports:
      - "9864:9864"
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./conf/hadoop.env
    restart: always

  datanode-2:
    image: trivadis/apache-hadoop-datanode:2.0.0-hadoop3.1.1-java8
    container_name: datanode-2
    volumes:
      - ./container-volume/datanode-2:/hadoop/dfs/data
    ports:
      - "9865:9864"
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./conf/hadoop.env
    restart: always

  hue:
    image: gethue/hue:4.4.0
    container_name: hue
    hostname: hue
    dns: 8.8.8.8
    ports:
      - "28888:8888"
    volumes:
      - ./conf/hue.ini:/usr/share/hue/desktop/conf/hue.ini
    depends_on:
      - hue-postgres
    restart: always

  hue-postgres:
    image: postgres:10
    container_name: hue-postgres
    hostname: hue-postgres
    environment:
      POSTGRES_DB: hue
      POSTGRES_PASSWORD: hue
      POSTGRES_USER: hue
    restart: always

  minio:
    image: minio/minio
    container_name: minio
    hostname: minio
    ports:
      - "9000:9000"
    volumes:
      - "./container-volume/minio/data/:/data"
    #      - './minio/config:/root/.minio'
    environment:
      MINIO_ACCESS_KEY: V42FCGRVMK24JJ8DHUYG
      MINIO_SECRET_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    command: server /data
    restart: always

  awscli:
    image: xueshanf/awscli
    container_name: awscli
    hostname: awscli
    volumes:
      - './conf/s3cfg:/root/.s3cfg'
      - './data-transfer:/data-transfer'
#      - './minio/config:/root/.minio'
    environment:
      AWS_ACCESS_KEY_ID: V42FCGRVMK24JJ8DHUYG
      AWS_SECRET_ACCESS_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    command: tail -f /dev/null
    restart: always

  spark-master:
    image: trivadis/apache-spark-master:2.4.4-hadoop2.7 
    container_name: spark-master
    hostname: spark-master
    ports:
      - 6066:6066
      - 7077:7077
      - 8080:8080
    env_file:
      - ./conf/hadoop.env  
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
      INIT_DAEMON_STEP: setup_spark
#      CORE_CONF_fs_defaultFS: hdfs://namenode:8020
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark-defaults.conf
      - ./credentials/s3.jceks:/credentials/s3.jceks
    restart: always

  spark-worker-1:
    image: trivadis/apache-spark-worker:2.4.4-hadoop2.7
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    env_file:
      - ./conf/hadoop.env  
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
#      SPARK_WORKER_CORES: 2
#      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_WEBUI_PORT: "8081"
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark-defaults.conf
    restart: always

  spark-worker-2:
    image: trivadis/apache-spark-worker:2.4.4-hadoop2.7
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    env_file:
      - ./conf/hadoop.env  
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
#      SPARK_WORKER_CORES: 2
#      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_WEBUI_PORT: "8082"
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
    volumes:
      - ./conf/spark/spark-defaults.conf:/spark/conf/spark-defaults.conf
    restart: always
